{
  "cells": [
    {
      "metadata": {
        "id": "8f50a9f66adbfc04"
      },
      "cell_type": "markdown",
      "source": [
        "# Image classification with transfer learning"
      ],
      "id": "8f50a9f66adbfc04"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Pre-processing**"
      ],
      "metadata": {
        "id": "aqK8Ze-jXYKr"
      },
      "id": "aqK8Ze-jXYKr"
    },
    {
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53ded9d92832209a",
        "outputId": "42e01c59-4ee4-44a3-e8c8-7302e898de27",
        "ExecuteTime": {
          "end_time": "2025-10-23T18:34:21.469130Z",
          "start_time": "2025-10-23T18:34:21.445128Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#Importing dataset from CIFAR\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Load CIFAR-10 dataset and print shapes\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "id": "53ded9d92832209a",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3)\n",
            "y_test shape: (10000, 1)\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-processing classes (y)**"
      ],
      "metadata": {
        "id": "M76nrQzctX1Z"
      },
      "id": "M76nrQzctX1Z"
    },
    {
      "metadata": {
        "id": "3d56960e9ba3f5de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0048ef39-99af-4f4a-e4ed-741ca151b5d0"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train_cat shape: (50000, 10)\n",
            "y_test_cat shape: (10000, 10)\n"
          ]
        }
      ],
      "execution_count": 10,
      "source": [
        "# convert classes into categories with one hot encoding and check shape.\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes)\n",
        "y_test_cat = to_categorical(y_test, num_classes)\n",
        "\n",
        "print(\"y_train_cat shape:\", y_train_cat.shape)\n",
        "print(\"y_test_cat shape:\", y_test_cat.shape)"
      ],
      "id": "3d56960e9ba3f5de"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-processing images**\n",
        "\n",
        "to make them compatible with the shapes and scales in our base model (MobileNetV2)\n"
      ],
      "metadata": {
        "id": "gnZmQVTNmau2"
      },
      "id": "gnZmQVTNmau2"
    },
    {
      "cell_type": "code",
      "source": [
        "# This Keras function is specifically designed to make images compatible with the MobileNetV2 model.\n",
        "# It involves scaling and shifting pixel values to [-1, 1], as the model was trained on.\n",
        "\n",
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "\n",
        "# Preprocess your data\n",
        "x_train = preprocess_input(x_train)\n",
        "x_test = preprocess_input(x_test)\n"
      ],
      "metadata": {
        "id": "XBNLm_5YmZQ3"
      },
      "id": "XBNLm_5YmZQ3",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "185fd38539db54fb"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 7,
      "source": [
        "# Since we are using a Transfer learning technique, we need to merge features and labels into datasets, so that they can be processed correctly at a later stage.\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
      ],
      "id": "185fd38539db54fb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the base model from the pre-trained convnets"
      ],
      "metadata": {
        "id": "8Fd0_7vmatdm"
      },
      "id": "8Fd0_7vmatdm"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "IMG_SHAPE = (32,32,3)\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "\n",
        "\n",
        "#Freeze the convolutional base to prevent the weights from being updated during training.\n",
        "base_model.trainable = False\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CwgEINaan6b",
        "outputId": "f61de7de-cdab-45a6-a89e-3e805a8519c9"
      },
      "id": "6CwgEINaan6b",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-788324976.py:3: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LOOKING GOOD UNTIL HERE"
      ],
      "metadata": {
        "id": "lK2FC_33xO6E"
      },
      "id": "lK2FC_33xO6E"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# get a batch of images from our dataset and pass it through base model to get feature maps\n",
        "image_batch, label_batch = next(iter(train_dataset))\n",
        "feature_batch = base_model(image_batch)\n",
        "print(f\"Feature batch shape: {feature_batch.shape}\")\n",
        "\n",
        "# Apply Global Average Pooling to convert feature maps to vectors\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(f\"Feature batch average shape: {feature_batch_average.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "-T_9sl80k5RR"
      },
      "id": "-T_9sl80k5RR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a classification head.\n",
        "# In our case, it will be 10 neurons dense since this is the number of categories.\n",
        "# Using Softmax as the activation function since this is the ideal choice for classification problems.\n",
        "prediction_layer = tf.keras.layers.Dense(10, activation='softmax')\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(f\"Prediction batch shape: {prediction_batch.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "klCher4ZpKij"
      },
      "id": "klCher4ZpKij",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_augmentation = tf.keras.Sequential([\n",
        "#    tf.keras.layers.RandomFlip('horizontal'),\n",
        "#    tf.keras.layers.RandomRotation(0.2),\n",
        "#])\n",
        "\n",
        "\n",
        "inputs = tf.keras.Input(shape=(32, 32, 3))\n",
        "#x = data_augmentation(x_train)\n",
        "x = preprocess_input(x_train)\n",
        "x = base_model(x, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "22r5-3KSpTDk"
      },
      "id": "22r5-3KSpTDk",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6548f999e5006af2"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "##block of code used to clear keras sessions during development\n",
        "\n",
        "#from keras.backend import clear_session\n",
        "#clear_session()"
      ],
      "id": "6548f999e5006af2"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CfkkmyMAr0sm"
      },
      "id": "CfkkmyMAr0sm",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "name": "python3",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}